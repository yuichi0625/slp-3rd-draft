{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9deee1b4",
   "metadata": {},
   "source": [
    "## 3.1\n",
    "Write out the equation for trigram probability estimation (modifying Eq. 3.11)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d08080",
   "metadata": {},
   "source": [
    "$\n",
    "P(w_{n}|w_{n-2}w_{n-1}) = \\displaystyle \\frac{C(w_{n-2}w_{n-1}w_{n})}{C(w_{n-2}w_{n-1})}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc7cb4d",
   "metadata": {},
   "source": [
    "Now write out all the non-zero trigram probabilities for the *I am Sam* corpus on page 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e336181d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trigram</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P(am | &lt;s&gt; I)</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P(Sam | I am)</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P(&lt;/s&gt; | am Sam)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P(I | &lt;s&gt; Sam)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P(am | Sam I)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P(&lt;/s&gt; | I am)</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P(do | &lt;s&gt; I)</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>P(not | I do)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>P(like | do not)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>P(green | not like)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>P(eggs | like green)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P(and | green eggs)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>P(ham | eggs and)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>P(&lt;/s&gt; | and ham)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 trigram  prob\n",
       "0          P(am | <s> I)   0.5\n",
       "1          P(Sam | I am)   0.5\n",
       "2       P(</s> | am Sam)   1.0\n",
       "3         P(I | <s> Sam)   1.0\n",
       "4          P(am | Sam I)   1.0\n",
       "5         P(</s> | I am)   0.5\n",
       "6          P(do | <s> I)   0.5\n",
       "7          P(not | I do)   1.0\n",
       "8       P(like | do not)   1.0\n",
       "9    P(green | not like)   1.0\n",
       "10  P(eggs | like green)   1.0\n",
       "11   P(and | green eggs)   1.0\n",
       "12     P(ham | eggs and)   1.0\n",
       "13     P(</s> | and ham)   1.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(\n",
    "    [['P(am | <s> I)', 0.5], ['P(Sam | I am)', 0.5], ['P(</s> | am Sam)', 1],\n",
    "     ['P(I | <s> Sam)', 1], ['P(am | Sam I)', 1], ['P(</s> | I am)', 0.5],\n",
    "     ['P(do | <s> I)', 0.5], ['P(not | I do)', 1], ['P(like | do not)', 1], ['P(green | not like)', 1],\n",
    "     ['P(eggs | like green)', 1], ['P(and | green eggs)', 1], ['P(ham | eggs and)', 1], ['P(</s> | and ham)', 1]],\n",
    "    columns=('trigram', 'prob')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89fcdcd",
   "metadata": {},
   "source": [
    "## 3.2\n",
    "Calculate the probability of the sentence *i want chinese food*. Give two probabilities, one using Fig. 3.2 and the ‘useful probabilities’ just below it on page 6,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6fc4428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00018961800000000004"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "P(i | <s>) = 0.25\n",
    "P(want | i) = 0.33\n",
    "P(chinese | want) = 0.0065\n",
    "P(food | chinese) = 0.52\n",
    "P(</s> | food) = 0.68\n",
    "\"\"\"\n",
    "0.25 * 0.33 * 0.0065 * 0.52 * 0.68"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f57e2d6",
   "metadata": {},
   "source": [
    "and another using the add-1 smoothed table in Fig. 3.6. Assume the additional add-1 smoothed probabilities $P(i|<s>) = 0.19$ and $P(</s>|food) = 0.40$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0640e614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4067679999999995e-06"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "P(i | <s>) = 0.19\n",
    "P(want | i) = 0.21\n",
    "P(chinese | want) = 0.0029\n",
    "P(food | chinese) = 0.052\n",
    "P(</s> | food) = 0.40\n",
    "\"\"\"\n",
    "0.19 * 0.21 * 0.0029 * 0.052 * 0.40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888d40f2",
   "metadata": {},
   "source": [
    "## 3.3\n",
    "Which of the two probabilities you computed in the previous exercise is higher, unsmoothed or smoothed? Explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbee2b0",
   "metadata": {},
   "source": [
    "**Answer**: unsmoothed  \n",
    "**Reason**: \"To keep a language model from assigning zero probability to these unseen events, we’ll have to shave off a bit of probability mass from some more frequent events and give it to the events we’ve never seen.\" (13 page 3-5 lines), which leads to the lower probability of the existing bigram."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cb4ba9",
   "metadata": {},
   "source": [
    "## 3.4\n",
    "We are given the following corpus, modified from the one in the chapter:  \n",
    "$<s>\\ I\\ am\\ Sam\\ </s>$  \n",
    "$<s>\\ Sam\\ I\\ am\\ </s>$  \n",
    "$<s>\\ I\\ am\\ Sam\\ </s>$  \n",
    "$<s>\\ I\\ do\\ not\\ like\\ green\\ eggs\\ and\\ Sam\\ </s>$  \n",
    "Using a bigram language model with add-one smoothing, what is $P(Sam | am)$? Include $<s>$ and $</s>$ in your counts just like any other token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b91172d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I</th>\n",
       "      <th>am</th>\n",
       "      <th>Sam</th>\n",
       "      <th>do</th>\n",
       "      <th>not</th>\n",
       "      <th>like</th>\n",
       "      <th>green</th>\n",
       "      <th>eggs</th>\n",
       "      <th>and</th>\n",
       "      <th>&lt;/s&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sam</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>do</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>green</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eggs</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         I   am  Sam   do  not  like  green  eggs  and  </s>\n",
       "<s>   0.29 0.07 0.14 0.07 0.07  0.07   0.07  0.07 0.07  0.07\n",
       "I     0.07 0.29 0.07 0.14 0.07  0.07   0.07  0.07 0.07  0.07\n",
       "am    0.08 0.08 0.23 0.08 0.08  0.08   0.08  0.08 0.08  0.15\n",
       "Sam   0.14 0.07 0.07 0.07 0.07  0.07   0.07  0.07 0.07  0.29\n",
       "do    0.09 0.09 0.09 0.09 0.18  0.09   0.09  0.09 0.09  0.09\n",
       "not   0.09 0.09 0.09 0.09 0.09  0.18   0.09  0.09 0.09  0.09\n",
       "like  0.09 0.09 0.09 0.09 0.09  0.09   0.18  0.09 0.09  0.09\n",
       "green 0.09 0.09 0.09 0.09 0.09  0.09   0.09  0.18 0.09  0.09\n",
       "eggs  0.09 0.09 0.09 0.09 0.09  0.09   0.09  0.09 0.18  0.09\n",
       "and   0.09 0.09 0.18 0.09 0.09  0.09   0.09  0.09 0.09  0.09"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    [[3, 0, 1, 0, 0, 0, 0, 0, 0, 0],  # <s>\n",
    "     [0, 3, 0, 1, 0, 0, 0, 0, 0, 0],  # I\n",
    "     [0, 0, 2, 0, 0, 0, 0, 0, 0, 1],  # am\n",
    "     [1, 0, 0, 0, 0, 0, 0, 0, 0, 3],  # Sam\n",
    "     [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],  # do\n",
    "     [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],  # not\n",
    "     [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],  # like\n",
    "     [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],  # green\n",
    "     [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],  # eggs\n",
    "     [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]], # and\n",
    "    columns=('I', 'am', 'Sam', 'do', 'not', 'like', 'green', 'eggs', 'and', '</s>'),\n",
    "    index=('<s>', 'I', 'am', 'Sam', 'do', 'not', 'like', 'green', 'eggs', 'and')\n",
    ")\n",
    "df_add1 = df + 1\n",
    "df_add1.div(df_add1.sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2132e7b4",
   "metadata": {},
   "source": [
    "## 3.5\n",
    "Suppose we didn’t use the end-symbol </s>. Train an unsmoothed bigram grammar on the following training corpus without using the end-symbol $</s>$:  \n",
    "$<s>\\ a\\ b$  \n",
    "$<s>\\ b\\ b$  \n",
    "$<s>\\ b\\ a$  \n",
    "$<s>\\ a\\ a$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb977fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       a    b\n",
       "<s> 0.50 0.50\n",
       "a   0.50 0.50\n",
       "b   0.50 0.50"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    [[2, 2],  # <s>\n",
    "     [1, 1],  # a\n",
    "     [1, 1]], # b\n",
    "    columns=('a', 'b'),\n",
    "    index=('<s>', 'a', 'b')\n",
    ")\n",
    "df.div(df.sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8b0213",
   "metadata": {},
   "source": [
    "Demonstrate that your bigram model does not assign a single probability distribution across all sentence lengths by showing that the sum of the probability of the four possible 2 word sentences over the alphabet {a,b} is 1.0,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f1dd158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "<s> a a\n",
    "<s> a b\n",
    "<s> b a\n",
    "<s> b b\n",
    "→どれも0.5 * 0.5になる\n",
    "\"\"\"\n",
    "0.5 * 0.5 * 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ed4bef",
   "metadata": {},
   "source": [
    "and the sum of the probability of all possible 3 word sentences over the alphabet {a,b} is also 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3913901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "<s> a a a\n",
    "<s> a a b\n",
    "<s> a b a\n",
    "<s> a b b\n",
    "...\n",
    "→どれも0.5 * 0.5 * 0.5になる\n",
    "\"\"\"\n",
    "0.5 * 0.5 * 0.5 * (2 ** 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048ce2d1",
   "metadata": {},
   "source": [
    "## 3.6\n",
    "Suppose we train a trigram language model with add-one smoothing on a given corpus. The corpus contains $V$ word types. Express a formula for estimating $P(w3|w1,w2)$, where $w3$ is a word which follows the bigram $(w1,w2)$, in terms of various N-gram counts and $V$. Use the notation $c(w1,w2,w3)$ to denote the number of times that trigram $(w1,w2,w3)$ occurs in the corpus, and so on for bigrams and unigrams."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222d4cb2",
   "metadata": {},
   "source": [
    "$\n",
    "P(w3|w1,w2) = \\displaystyle \\frac{c(w1,w2,w3) + 1}{c(w1,w2) + V}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a101e3",
   "metadata": {},
   "source": [
    "## 3.7\n",
    "We are given the following corpus, modified from the one in the chapter:  \n",
    "$<s>\\ I\\ am\\ Sam\\ </s>$  \n",
    "$<s>\\ Sam\\ I\\ am\\ </s>$  \n",
    "$<s>\\ I\\ am\\ Sam\\ </s>$  \n",
    "$<s>\\ I\\ do\\ not\\ like\\ green\\ eggs\\ and\\ Sam\\ </s>$  \n",
    "If we use linear interpolation smoothing between a maximum-likelihood bigram model and a maximum-likelihood unigram model with $λ_{1} = \\frac{1}{2}$ and $λ_{2} = \\frac{1}{2}$, what is $P(Sam|am)$? Include $<s>$ and $</s>$ in your counts just like any other token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0db28515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41333333333333333"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "P(Sam|am) with linear interpolation = λ2 * P(Sam|am) + λ1 * P(Sam)\n",
    "P(Sam|am) = C(am,Sam) / C(am)\n",
    "C(am,Sam) = 2\n",
    "C(am) = 3\n",
    "P(Sam) = C(Sam) / C(*)\n",
    "C(Sam) = 4\n",
    "C(*) = 25\n",
    "\"\"\"\n",
    "0.5 * (2 / 3) + 0.5 * (4 / 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7ee822",
   "metadata": {},
   "source": [
    "## 3.8\n",
    "Write a program to compute unsmoothed unigrams and bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61f79e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "class Ngram:\n",
    "    def __init__(self):\n",
    "        self.unigram = {}\n",
    "        self.bigram = {}\n",
    "\n",
    "    def train(self, sentences):\n",
    "        unigram = defaultdict(int)\n",
    "        bigram = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "        for sentence in tqdm(sentences):\n",
    "            words = self._tokenize(sentence)\n",
    "\n",
    "            # unigram\n",
    "            for word in words[:-1]:\n",
    "                unigram[word] += 1\n",
    "\n",
    "            # bigram\n",
    "            for i in range(len(words) - 1):\n",
    "                bigram[words[i]][words[i+1]] += 1\n",
    "\n",
    "        # normalize unigram\n",
    "        sum_ = sum(unigram.values())\n",
    "        self.unigram = {word: count / sum_ for word, count in unigram.items()}\n",
    "\n",
    "        # normalize bigram\n",
    "        for word, d in bigram.items():\n",
    "            sum_ = sum(d.values())\n",
    "            self.bigram[word] = {word: count / sum_ for word, count in d.items()}\n",
    "\n",
    "    def _tokenize(self, sentence):\n",
    "        puncts = set(',.!?\\'\"')\n",
    "        words = [word for word in word_tokenize(sentence) if word not in puncts]\n",
    "        words = ['<s>'] + words + ['</s>']\n",
    "        return words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c860b101",
   "metadata": {},
   "source": [
    "## 3.9\n",
    "Run your n-gram program on two different small corpora of your choice (you might use email text or newsgroups). Now compare the statistics of the two corpora. What are the differences in the most common unigrams between the two? How about interesting differences in bigrams?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d029009e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0bc11ae",
   "metadata": {},
   "source": [
    "## 3.10\n",
    "Add an option to your program to generate random sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b8b8d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "class Ngram10(Ngram):\n",
    "    def generate_random_sentence(self, max_len=50):\n",
    "        curr = '<s>'\n",
    "        words = [curr]\n",
    "        while len(words) < max_len:\n",
    "            curr = random.choice(list(self.bigram[curr].keys()))\n",
    "            words.append(curr)\n",
    "            if curr == '</s>':\n",
    "                break\n",
    "        return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f38073b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://tatoeba.org/jpn/downloads\n",
    "# https://downloads.tatoeba.org/exports/per_language/eng/eng_sentences.tsv.bz2\n",
    "with open('eng_sentences.tsv', encoding='utf-8') as f:\n",
    "    sents = []\n",
    "    for line in iter(f.readline, ''):\n",
    "        line = line.rstrip()\n",
    "        if line:\n",
    "            *_, sent = line.split('\\t')\n",
    "            sents.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45593705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8777f2709f8f4479806ed5ee5011530c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1461720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ngram10 = Ngram10()\n",
    "ngram10.train(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58adc836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Tidal highs and Guantanamo 's has guts do just cry was staggeringly ignorant like Des Moines and skittles </s>\n",
      "<s> Putin during Hari was prepaid mobile again ” building pulled dozens more expensive would send threatening his operas `` Google Amazing '' seems sure been cloudy It shall grace which unfortunately there Only yogurt and tumbling after autumn swallows that definitely regret for corrections </s>\n",
      "<s> Kabuki doll her bamboo is doctored his damaged soil food commercial port wine are fated will swear words there Please be ticketed </s>\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "for _ in range(3):\n",
    "    print(ngram10.generate_random_sentence())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74fa108",
   "metadata": {},
   "source": [
    "## 3.11\n",
    "Add an option to your program to compute the perplexity of a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba1c50d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ngram11(Ngram):\n",
    "    def compute_perplexity(self, sentence, n=1):\n",
    "        assert n in {1, 2}\n",
    "\n",
    "        words = self._tokenize(sentence)\n",
    "        pp = 1\n",
    "        \n",
    "        if n == 1:\n",
    "            for word in words[:-1]:\n",
    "                prob = self.unigram.get(word, 0)\n",
    "                pp *= 1 / prob if prob else prob\n",
    "\n",
    "        else:\n",
    "            for i in range(len(words) - 1):\n",
    "                prev, curr = words[i:i+2]\n",
    "                tmp = self.bigram.get(prev, 0)\n",
    "                prob = tmp.get(curr, 0) if tmp else tmp\n",
    "                pp *= 1 / prob if prob else prob\n",
    "\n",
    "        return pow(pp, 1 / (len(words) - 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "397550b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "777bf894dc074fe5baee801d7064ec58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1461720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ngram11 = Ngram11()\n",
    "ngram11.train(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7e84463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigram: 870.1391571409932\n",
      " bigram: 68.40238590983533\n"
     ]
    }
   ],
   "source": [
    "sent = 'Mary thinks she wants to marry tom, but she is not able to take the last step.'\n",
    "\n",
    "print(f'unigram: {ngram11.compute_perplexity(sent, n=1)}')\n",
    "print(f' bigram: {ngram11.compute_perplexity(sent, n=2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af91e3b6",
   "metadata": {},
   "source": [
    "## 3.12\n",
    "You are given a training set of 100 numbers that consists of 91 zeros and 1 each of the other digits 1-9. Now we see the following test set: 0 0 0 0 0 3 0 0 0 0. What is the unigram perplexity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e40f4768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.693609475280226"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "0  : 91/100\n",
    "1-9: 1/100\n",
    "\"\"\"\n",
    "inv_prob_0 = 100 / 91\n",
    "inv_prob_1_9 = 100 / 1\n",
    "\n",
    "pow(inv_prob_1_9 ** 9 * inv_prob_0, 1 / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d29ef79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
